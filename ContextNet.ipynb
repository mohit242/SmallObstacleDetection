{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage import io\n",
    "import numpy as np\n",
    "class ContextNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ContextNet,self).__init__()\n",
    "        \n",
    "        self.conv1_a = nn.Conv2d(3,64,3)\n",
    "        self.bnorm1_a = nn.BatchNorm2d(64)\n",
    "        self.conv1_b = nn.Conv2d(64,64,3)\n",
    "        self.bnorm1_b = nn.BatchNorm2d(64)\n",
    "        self.pool1 = nn.MaxPool2d(2,return_indices=True)\n",
    "        \n",
    "        self.conv2_a = nn.Conv2d(64,128,3)\n",
    "        self.bnorm2_a = nn.BatchNorm2d(128)\n",
    "        self.conv2_b = nn.Conv2d(128,128,3)\n",
    "        self.bnorm2_b = nn.BatchNorm2d(128)\n",
    "        self.pool2 = nn.MaxPool2d(2,return_indices=True)\n",
    "        \n",
    "        self.conv3_a = nn.Conv2d(128,256,3)\n",
    "        self.bnorm3_a = nn.BatchNorm2d(256)\n",
    "        self.conv3_b = nn.Conv2d(256,256,3)\n",
    "        self.bnorm3_b = nn.BatchNorm2d(256)\n",
    "        self.conv3_c = nn.Conv2d(256,256,3)\n",
    "        self.bnorm3_c = nn.BatchNorm2d(256)\n",
    "        self.pool3 = nn.MaxPool2d(2,return_indices=True)\n",
    "        \n",
    "        self.unpool4 = nn.MaxUnpool2d(2)\n",
    "        self.conv4_a = nn.Conv2d(256,256,3,padding=2)\n",
    "        self.bnorm4_a = nn.BatchNorm2d(256)\n",
    "        self.conv4_b = nn.Conv2d(256,256,3,padding=2)\n",
    "        self.bnorm4_b = nn.BatchNorm2d(256)\n",
    "        self.conv4_c = nn.Conv2d(256,128,3,padding=2)\n",
    "        self.bnorm4_c = nn.BatchNorm2d(128)\n",
    "        \n",
    "        self.unpool5 = nn.MaxUnpool2d(2)\n",
    "        self.conv5_a = nn.Conv2d(128,128,3,padding=2)\n",
    "        self.bnorm5_a = nn.BatchNorm2d(128)\n",
    "        self.conv5_b = nn.Conv2d(128,64,3,padding=2)\n",
    "        self.bnorm5_b = nn.BatchNorm2d(64)\n",
    "        \n",
    "        self.unpool6 = nn.MaxUnpool2d(2)\n",
    "        self.conv6_a = nn.Conv2d(64,64,3,padding=2)\n",
    "        self.bnorm6_a = nn.BatchNorm2d(64)\n",
    "        self.conv6_b = nn.Conv2d(64,3,3,padding=2)\n",
    "        self.bnorm6_b = nn.BatchNorm2d(3)\n",
    "#         self.softmax = nn.Softmax2d()\n",
    "\n",
    "    def forward(self,x):\n",
    "        \n",
    "        y = F.relu(self.bnorm1_a(self.conv1_a(x)))\n",
    "        y = F.relu(self.bnorm1_b(self.conv1_b(y)))\n",
    "        pool_size1=y.size()\n",
    "        y,ind1=self.pool1(y)\n",
    "        \n",
    "        y = F.relu(self.bnorm2_a(self.conv2_a(y)))\n",
    "        y = F.relu(self.bnorm2_b(self.conv2_b(y)))\n",
    "        pool_size2=y.size()\n",
    "        y,ind2=self.pool2(y)\n",
    "        \n",
    "        y = F.relu(self.bnorm3_a(self.conv3_a(y)))\n",
    "        y = F.relu(self.bnorm3_b(self.conv3_b(y)))\n",
    "        y = F.relu(self.bnorm3_c(self.conv3_c(y)))\n",
    "        pool_size3=y.size()\n",
    "        y,ind3=self.pool3(y)\n",
    "        \n",
    "        y = self.unpool4(y,ind3,output_size=pool_size3)\n",
    "        y = F.relu(self.bnorm4_a(self.conv4_a(y)))\n",
    "        y = F.relu(self.bnorm4_b(self.conv4_b(y)))\n",
    "        y = F.relu(self.bnorm4_c(self.conv4_c(y)))\n",
    "        \n",
    "        y = self.unpool5(y,ind2,output_size=pool_size2)\n",
    "        y = F.relu(self.bnorm5_a(self.conv5_a(y)))\n",
    "        y = F.relu(self.bnorm5_b(self.conv5_b(y)))\n",
    "        \n",
    "        y = self.unpool4(y,ind1,output_size=pool_size1)\n",
    "        y = F.relu(self.bnorm6_a(self.conv6_a(y)))\n",
    "        y = F.relu(self.bnorm6_b(self.conv6_b(y)))\n",
    "        \n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms,utils\n",
    "import re,glob\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage import io\n",
    "from skimage.transform import resize\n",
    "import torch\n",
    "class ObstacleDataset(Dataset):\n",
    "    def __init__(self,files,transforms=None):\n",
    "        #super(ObstacleDataset,self).__init__()\n",
    "        self.files=files\n",
    "        self.transforms=transforms\n",
    "    \n",
    "    def __len__(self):\n",
    "        return(len(self.files))\n",
    "    \n",
    "    def __getitem__(self,idx):\n",
    "        file = self.files[idx]\n",
    "        rgb = io.imread(file[0])\n",
    "        segmentation_mask = io.imread(file[1])\n",
    "        sample = {'rgb': rgb,'mask': segmentation_mask}\n",
    "        if self.transforms:\n",
    "            sample = self.transforms(sample)\n",
    "        \n",
    "        return sample\n",
    "\n",
    "class RandomHorizontalFlip(object):\n",
    "    \"\"\"Randomly flips images in a sample in the horizontal direction\n",
    "    \n",
    "    Args:\n",
    "        prob: probability of horizontal flip\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self,prob=0.5):\n",
    "        self.prob= prob\n",
    "    \n",
    "    def __call__(self,sample):\n",
    "        do_flip = np.random.rand()\n",
    "        if do_flip<self.prob:\n",
    "            return sample\n",
    "        rgb,mask = sample['rgb'],sample['mask']\n",
    "        rgb = np.flip(rgb,1)\n",
    "        mask = np.flip(mask,1)\n",
    "        return {'rgb':rgb,'mask':mask}\n",
    "    \n",
    "class ToTensor(object):\n",
    "    \"\"\"Converts ndarrys in sample to Tensors\"\"\"\n",
    "    def __call__(self,sample):\n",
    "        rgb,mask = sample['rgb'],sample['mask']\n",
    "        rgb = rgb.transpose((2,0,1))\n",
    "        mask[mask==255]=0\n",
    "        # perform one-hot encoding on mask later if required\n",
    "        rgb=torch.from_numpy(np.flip(rgb,axis=0).copy())\n",
    "        return {'rgb':rgb.type(\"torch.FloatTensor\"),\n",
    "               'mask':torch.from_numpy(mask.copy(),)}\n",
    "class Normalize(object):\n",
    "    \"\"\"Performs normalization on Tensor\"\"\"\n",
    "    def __call__(self,sample):\n",
    "        rgb,mask=sample['rgb'],sample['mask']\n",
    "        norm = transforms.Normalize(mean=[0.5,0.5,0.5],std=[0.5,0.5,0.5])\n",
    "        rgb=norm(rgb)\n",
    "        return {'rgb':rgb,'mask':mask}\n",
    "class Resize(object):\n",
    "    def __call__(self,sample):\n",
    "        rgb,mask=sample['rgb'],sample['mask']\n",
    "        rgb=resize(rgb, (rgb.shape[0] / 4, rgb.shape[1] / 4))\n",
    "        mask=resize(mask, (mask.shape[0] / 4, mask.shape[1] / 4))\n",
    "        return {'rgb':rgb,'mask':mask}\n",
    "        \n",
    "def show_examples(sample_batch):\n",
    "    rgb_batch,mask_batch = sample_batch['rgb'],sample_batch['mask']\n",
    "    rgb_grid= utils.make_grid(rgb_batch)\n",
    "    mask_grid= utils.make_grid(mask_batch)\n",
    "    \n",
    "    ax = plt.subplot(211)\n",
    "    ax.axis(\"off\")\n",
    "    plt.imshow(rgb_grid.numpy().transpose((1,2,0)))\n",
    "    ax = plt.subplot(212)\n",
    "    ax.axis(\"off\")\n",
    "    plt.imshow(100*mask_grid.numpy().transpose((1,2,0)))\n",
    "    return\n",
    "    \n",
    "\n",
    "img_files={}\n",
    "for x in [\"train\",\"test\"]:\n",
    "    img_files[x] = glob.glob(\"/home/mohit/leftImg8bit/\"+x+\"/*/*.png\")\n",
    "\n",
    "files={\"train\":[],\"test\":[]}\n",
    "\n",
    "for x in [\"train\",\"test\"]:\n",
    "    for ifile in img_files[x]:\n",
    "        path = re.search(\"/home/mohit/leftImg8bit/(.*)_leftImg8bit.png\",ifile)\n",
    "        files[x].append([ifile,\"/home/mohit/gtCoarse/\"+path.group(1)+\"_gtCoarse_labelTrainIds.png\"])\n",
    "        \n",
    "tnfs = transforms.Compose([RandomHorizontalFlip(),ToTensor()])\n",
    "\n",
    "obs_dataset = {'train':ObstacleDataset(files[\"train\"],tnfs),\n",
    "               'test':ObstacleDataset(files['test'],tnfs)}\n",
    "\n",
    "dataloader = {x:DataLoader(obs_dataset[x],batch_size=2,\n",
    "                          shuffle=True,num_workers=1) for x in ['train','test']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "def train_model(model,criterion,optimizer,scheduler=None,num_epochs=100):\n",
    "    start = time.time()\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch,num_epochs-1))\n",
    "        print('-'*12)\n",
    "        \n",
    "        if scheduler:\n",
    "            scheduler.step()\n",
    "        model.train()\n",
    "        pixel_detection_rate = 0.0\n",
    "\n",
    "        for sample in dataloader['train']:\n",
    "            inputs = sample['rgb']\n",
    "            masks = sample['mask']\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "#             outputs = model(inputs)\n",
    "            print(np.unique(masks.numpy()))\n",
    "#             loss = criterion(outputs,masks)\n",
    "#             print(\"loss: \",loss)\n",
    "#             loss.backward()\n",
    "#             optimizer.step()\n",
    "            break\n",
    "        time_elap= time.time()-start\n",
    "        start=time.time()\n",
    "        print(\"Time elapsed: {:.0f}:{:.0f}\".format(time_elap//60,time_elap%60))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "model = ContextNet()\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "train_model(model,criterion,optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = next(iter(dataloader['train']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=ContextNet()\n",
    "outputs=model(sample['rgb'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (deep_learning)",
   "language": "python",
   "name": "deep_learning"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
